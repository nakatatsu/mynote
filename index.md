# My Summary

## AI利用の原則

1. セーフティファースト
    * 致命的な結果をもたらすような権限を決してAIに与えてはいけない
        * e.g., 機密情報の流出、重要なデータの破壊などに繋がる権限は最初からすべてシャットアウト
    * そのほかはリスクに応じた防御策を
        * 情報の流出リスクをオプションや契約、保険契約で担保するなど
        * 作業場のリスクゼロを求めるとAI利用をあきらめるしかない。だがAI利用を避けること自体がビジネス上の巨大なリスクである
    * 安全が確保されているからこそ積極的に利用できる。セキュリティは邪魔者ではない
2. 十分なコンテキストの用意
    * 必要な情報やツールへのアクセスが良好な生成の土台
    * リスクを許容できる範囲内で上限いっぱいの権限を渡せるのが望ましい
3. 精度に応じたプロンプトの作りこみ
    * ちょっとした内容は思いついたままに聞けば十分。それでも今のAIなら十分な回答を返してくる
    * 高い精度が必要な作業はコンテキストエンジニアリングやプロンプトエンジニアリングを考えるといい
        * そしてできればプロンプトはSkillsなどの機能を使って使いまわす。何度もプロンプトを考えるのは大変なので

## コンテキストエンジニアリング（プロンプトエンジニアリング含む）

* 生成に必要な情報を十分渡し、ノイズ情報を極力減らす
    * 精度を上げ、コストを減らす最良の手段
* 気づきづらいノイズ源は最小限に
    * 自動挿入コンテキストに大量のノイズが含まれていることがある。そういうものを極力減らす。
        * 例えばClaude CodeのCLAUDE.mdと履歴。
* 巨大すぎるプロンプトが必要になるなら、タスクを分割して小さくする
* スクリプトやツールで済むものはそちらを使う
    * そのためのスクリプトやツールをAIに作らせればよい
* 指示を出す前に調査・確認する
    * 雑な指示で生成させたところで全部捨てるはめになる。私はそれで何度も捨てた
* MCP, 公式スキルなどは積極的に利用を
    * あれこれ自分で考えるより良質なものが早く手に入る
* 渡したプロンプトの再現性・トレーサビリティを確保する
    * なにも工夫しないとこうなる「もう一回同じ指示を出したくても出せない。なぜそうなったのかもわからない」
        * これでは途中から生成させなおすことができない
        * 生成されたものが指示通りか確認する術もない（指示が残ってないから）



## SpecDriven


























